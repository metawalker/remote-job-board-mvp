// Generated by Copilot
// Script to apply the scraping sources migration to Supabase

const { createClient } = require('@supabase/supabase-js')
const fs = require('fs')
const path = require('path')

// Supabase configuration
const supabaseUrl = 'https://czvkltyhkzbuvsvqdlun.supabase.co'
const supabaseServiceKey = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN6dmtsdHloa3pidXZzdnFkbHVuIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MDUxMTgxMSwiZXhwIjoyMDY2MDg3ODExfQ.g-EmjKB06zXK46-2AdupzKXhTsEePklWuBgqBqNCbTI'

async function applyMigration() {
  const supabase = createClient(supabaseUrl, supabaseServiceKey)
  
  try {
    // Read the migration file
    const migrationPath = path.join(__dirname, 'supabase', 'scraping-sources-migration.sql')
    const migrationSQL = fs.readFileSync(migrationPath, 'utf8')
    
    console.log('Applying scraping sources migration...')
    
    // Execute the migration
    const { data, error } = await supabase.rpc('exec_sql', { sql: migrationSQL })
    
    if (error) {
      console.error('Migration failed:', error)
      
      // Try alternative method - execute parts of the migration manually
      console.log('Trying alternative migration approach...')
      
      // Create the table
      const createTableSQL = `
        CREATE TABLE IF NOT EXISTS scraping_sources (
            id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            url TEXT NOT NULL,
            enabled BOOLEAN DEFAULT true,
            description TEXT,
            priority VARCHAR(20) DEFAULT 'medium' CHECK (priority IN ('low', 'medium', 'high')),
            config JSONB DEFAULT '{}',
            last_scraped_at TIMESTAMP WITH TIME ZONE,
            total_jobs_found INTEGER DEFAULT 0,
            success_rate DECIMAL(5,2) DEFAULT 100.0,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            created_by UUID REFERENCES auth.users(id),
            updated_by UUID REFERENCES auth.users(id)
        );
      `
      
      const { error: createError } = await supabase.rpc('exec_sql', { sql: createTableSQL })
      
      if (createError) {
        console.error('Table creation failed:', createError)
        return
      }
      
      console.log('âœ… Table created successfully')
      
      // Insert default sources
      const { error: insertError } = await supabase
        .from('scraping_sources')
        .insert([
          {
            name: 'YCombinator Jobs',
            url: 'https://www.ycombinator.com/jobs',
            enabled: true,
            description: 'Y Combinator startup jobs',
            priority: 'high'
          },
          {
            name: 'We Work Remotely',
            url: 'https://weworkremotely.com/remote-jobs',
            enabled: true,
            description: 'Remote work job board',
            priority: 'medium'
          },
          {
            name: 'Google Careers',
            url: 'https://careers.google.com/jobs/results/',
            enabled: true,
            description: 'Google career opportunities',
            priority: 'high'
          }
        ])
      
      if (insertError) {
        console.error('Error inserting default sources:', insertError)
        return
      }
      
      console.log('âœ… Default scraping sources inserted')
      
    } else {
      console.log('âœ… Migration applied successfully')
      
      // Insert default sources
      const { error: insertError } = await supabase
        .from('scraping_sources')
        .insert([
          {
            name: 'YCombinator Jobs',
            url: 'https://www.ycombinator.com/jobs',
            enabled: true,
            description: 'Y Combinator startup jobs',
            priority: 'high'
          },
          {
            name: 'We Work Remotely',
            url: 'https://weworkremotely.com/remote-jobs',
            enabled: true,
            description: 'Remote work job board',
            priority: 'medium'
          },
          {
            name: 'Google Careers',
            url: 'https://careers.google.com/jobs/results/',
            enabled: true,
            description: 'Google career opportunities',
            priority: 'high'
          }
        ])
      
      if (insertError) {
        console.error('Error inserting default sources (might already exist):', insertError)
      } else {
        console.log('âœ… Default scraping sources inserted')
      }
    }
    
    // Verify the table exists and has data
    const { data: sources, error: selectError } = await supabase
      .from('scraping_sources')
      .select('*')
    
    if (selectError) {
      console.error('Error verifying sources:', selectError)
    } else {
      console.log(`âœ… Verification successful - ${sources.length} scraping sources found`)
      sources.forEach((source, index) => {
        console.log(`  ${index + 1}. ${source.name}: ${source.url}`)
      })
    }
    
    console.log('\nðŸŽ‰ Migration completed! The admin dashboard should now show actual URLs instead of placeholders.')
    
  } catch (error) {
    console.error('Unexpected error:', error)
  }
}

applyMigration()
