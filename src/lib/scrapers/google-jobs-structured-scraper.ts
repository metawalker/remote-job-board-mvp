// Generated by Copilot
import * as cheerio from 'cheerio'
import axios from 'axios'

export interface GoogleJobListing {
  title: string
  company: string
  location: string
  description: string
  employmentType?: string
  remoteType?: string
  salaryText?: string
  applyUrl?: string
  postedAt?: string
  skills?: string[]
}

export class GoogleJobsStructuredScraper {
  private maxRetries = 3
  private delayBetweenRequests = 2000 // 2 seconds delay between requests

  private userAgents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0'
  ]

  async scrapeRemoteJobs(query = 'remote software developer', location = 'United States', maxPages = 3): Promise<GoogleJobListing[]> {
    console.log(`Starting structured Google Jobs scraping for: ${query}`)
    const jobs: GoogleJobListing[] = []

    try {
      for (let page = 0; page < maxPages; page++) {
        console.log(`Scraping page ${page + 1}...`)
        
        const pageJobs = await this.scrapePage(query, location, page)
        jobs.push(...pageJobs)

        if (pageJobs.length === 0) {
          console.log('No more jobs found, stopping pagination')
          break
        }

        // Delay between pages
        if (page < maxPages - 1) {
          await new Promise(resolve => setTimeout(resolve, this.delayBetweenRequests))
        }
      }

      console.log(`Total jobs scraped: ${jobs.length}`)
      return jobs

    } catch (error) {
      console.error('Error in structured Google Jobs scraping:', error)
      throw error
    }
  }

  private async scrapePage(query: string, location: string, page: number): Promise<GoogleJobListing[]> {
    const start = page * 10 // Google uses start parameter for pagination
    const searchUrl = this.buildSearchUrl(query, location, start)

    try {
      const response = await this.makeRequest(searchUrl)
      const $ = cheerio.load(response.data)

      return this.extractJobsFromHtml($)
    } catch (error) {
      console.error(`Error scraping page ${page + 1}:`, error)
      return []
    }
  }

  private buildSearchUrl(query: string, location: string, start: number = 0): string {
    const baseUrl = 'https://www.google.com/search'
    const params = new URLSearchParams({
      q: query,
      l: location,
      ibp: 'htl;jobs',
      start: start.toString(),
      hl: 'en',
      gl: 'us'
    })

    return `${baseUrl}?${params.toString()}`
  }

  private async makeRequest(url: string): Promise<any> {
    const userAgent = this.userAgents[Math.floor(Math.random() * this.userAgents.length)]
    
    const config = {
      headers: {
        'User-Agent': userAgent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none'
      },
      timeout: 30000,
      validateStatus: (status: number) => status < 500 // Accept 4xx as valid
    }

    for (let attempt = 0; attempt < this.maxRetries; attempt++) {
      try {
        const response = await axios.get(url, config)
        
        if (response.status === 200) {
          return response
        }
        
        console.warn(`Attempt ${attempt + 1} failed with status ${response.status}`)
        
      } catch (error: any) {
        console.warn(`Attempt ${attempt + 1} failed:`, error.message)
        
        if (attempt === this.maxRetries - 1) {
          throw error
        }
        
        // Exponential backoff
        const delay = Math.pow(2, attempt) * 1000
        await new Promise(resolve => setTimeout(resolve, delay))
      }
    }

    throw new Error('All retry attempts failed')
  }

  private extractJobsFromHtml($: cheerio.CheerioAPI): GoogleJobListing[] {
    const jobs: GoogleJobListing[] = []

    try {
      // Try multiple selectors for job listings
      const jobSelectors = [
        '[data-ved][jsname]', // Primary selector
        '.job-bixbox',
        '.BYM4Nd',
        '[role="listitem"]'
      ]

      let jobElements: cheerio.Cheerio<any> | null = null

      for (const selector of jobSelectors) {
        jobElements = $(selector)
        if (jobElements.length > 0) {
          console.log(`Found ${jobElements.length} job elements using selector: ${selector}`)
          break
        }
      }

      if (!jobElements || jobElements.length === 0) {
        console.warn('No job elements found with any selector')
        return []
      }

      jobElements.each((index, element) => {
        try {
          const jobData = this.extractJobFromElement($, $(element))
          if (jobData && this.isValidJob(jobData) && this.isRemoteJob(jobData)) {
            jobs.push(jobData)
          }
        } catch (error) {
          console.warn(`Error extracting job ${index}:`, error)
        }
      })

      // Try to extract from JSON-LD structured data as fallback
      if (jobs.length === 0) {
        const structuredJobs = this.extractFromStructuredData($)
        jobs.push(...structuredJobs)
      }

      return jobs

    } catch (error) {
      console.error('Error extracting jobs from HTML:', error)
      return []
    }
  }

  private extractJobFromElement($: cheerio.CheerioAPI, element: cheerio.Cheerio<any>): GoogleJobListing | null {
    try {
      // Try multiple selectors for each field
      const titleSelectors = ['h3', '.jobTitle', '[data-test-id="job-title"]', 'div[role="heading"]']
      const companySelectors = ['.companyName', '[data-test-id="employer-name"]', '.BjJfJf', 'span[class*="company"]']
      const locationSelectors = ['.locationsContainer', '[data-test-id="job-location"]', '.Qk80Jf', 'span[class*="location"]']
      const descriptionSelectors = ['.jobDescription', '[data-test-id="job-description"]', '.HBvzbc', 'div[class*="description"]']

      const title = this.extractTextFromSelectors($, element, titleSelectors)
      const company = this.extractTextFromSelectors($, element, companySelectors)
      const location = this.extractTextFromSelectors($, element, locationSelectors)
      const description = this.extractTextFromSelectors($, element, descriptionSelectors)

      if (!title || !company) {
        return null
      }

      const job: GoogleJobListing = {
        title: title.trim(),
        company: company.trim(),
        location: location?.trim() || '',
        description: description?.trim() || ''
      }

      // Try to extract additional fields
      const salarySelectors = ['.salary', '[data-test-id="salary-range"]', '.ZdPLlf']
      const applySelectors = ['a[href*="apply"]', 'a[data-test-id="apply-button"]', 'a[aria-label*="Apply"]']

      job.salaryText = this.extractTextFromSelectors($, element, salarySelectors) || undefined
      job.applyUrl = this.extractHrefFromSelectors($, element, applySelectors) || undefined

      return this.processJobData(job)

    } catch (error) {
      console.warn('Error extracting individual job:', error)
      return null
    }
  }

  private extractTextFromSelectors($: cheerio.CheerioAPI, element: cheerio.Cheerio<any>, selectors: string[]): string | null {
    for (const selector of selectors) {
      const text = element.find(selector).first().text().trim()
      if (text) {
        return text
      }
    }
    return null
  }

  private extractHrefFromSelectors($: cheerio.CheerioAPI, element: cheerio.Cheerio<any>, selectors: string[]): string | null {
    for (const selector of selectors) {
      const href = element.find(selector).first().attr('href')
      if (href) {
        return href.startsWith('http') ? href : `https://www.google.com${href}`
      }
    }
    return null
  }

  private extractFromStructuredData($: cheerio.CheerioAPI): GoogleJobListing[] {
    const jobs: GoogleJobListing[] = []

    try {
      $('script[type="application/ld+json"]').each((_, element) => {
        try {
          const jsonText = $(element).html()
          if (!jsonText) return

          const data = JSON.parse(jsonText)
          
          if (data['@type'] === 'JobPosting' || (Array.isArray(data) && data.some((item: any) => item['@type'] === 'JobPosting'))) {
            const jobPostings = Array.isArray(data) ? data.filter((item: any) => item['@type'] === 'JobPosting') : [data]
            
            jobPostings.forEach((posting: any) => {
              const job: GoogleJobListing = {
                title: posting.title || '',
                company: posting.hiringOrganization?.name || '',
                location: posting.jobLocation?.address?.addressLocality || posting.jobLocation?.address || '',
                description: posting.description || '',
                employmentType: posting.employmentType?.toLowerCase(),
                salaryText: posting.baseSalary ? `${posting.baseSalary.currency} ${posting.baseSalary.value.value}` : undefined,
                applyUrl: posting.url
              }

              if (this.isValidJob(job) && this.isRemoteJob(job)) {
                jobs.push(this.processJobData(job))
              }
            })
          }
        } catch (error) {
          // Ignore JSON parsing errors
        }
      })
    } catch (error) {
      console.warn('Error extracting structured data:', error)
    }

    return jobs
  }

  private processJobData(job: GoogleJobListing): GoogleJobListing {
    // Process employment type
    if (!job.employmentType) {
      const title = job.title.toLowerCase()
      const description = job.description.toLowerCase()
      
      if (title.includes('intern') || description.includes('internship')) {
        job.employmentType = 'internship'
      } else if (title.includes('contract') || title.includes('freelance') || description.includes('contractor')) {
        job.employmentType = 'contract'
      } else if (title.includes('part-time') || title.includes('part time')) {
        job.employmentType = 'part-time'
      } else {
        job.employmentType = 'full-time'
      }
    }

    // Process remote type
    const locationText = job.location.toLowerCase()
    if (locationText.includes('remote') || locationText.includes('anywhere') || locationText.includes('work from home')) {
      job.remoteType = 'fully-remote'
    } else if (locationText.includes('hybrid')) {
      job.remoteType = 'hybrid'
    } else {
      job.remoteType = 'remote-allowed'
    }

    // Extract skills
    job.skills = this.extractSkills(job.description)

    return job
  }

  private extractSkills(description: string): string[] {
    const skillKeywords = [
      'JavaScript', 'TypeScript', 'React', 'Vue', 'Angular', 'Node.js', 'Python', 'Java',
      'C#', 'PHP', 'Ruby', 'Go', 'Rust', 'Swift', 'Kotlin', 'SQL', 'MongoDB', 'PostgreSQL',
      'AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'Git', 'GraphQL', 'REST', 'API',
      'HTML', 'CSS', 'SASS', 'Next.js', 'Express', 'Django', 'Flask', 'Spring', 'Laravel'
    ]

    const skills: string[] = []
    const descLower = description.toLowerCase()

    skillKeywords.forEach(skill => {
      if (descLower.includes(skill.toLowerCase())) {
        skills.push(skill)
      }
    })

    return Array.from(new Set(skills)) // Remove duplicates
  }

  private isValidJob(job: GoogleJobListing): boolean {
    return !!(job.title && job.company && job.title.length > 2 && job.company.length > 1)
  }

  private isRemoteJob(job: GoogleJobListing): boolean {
    const searchTerms = ['remote', 'work from home', 'telecommute', 'distributed', 'anywhere', 'wfh']
    const textToSearch = `${job.title} ${job.location} ${job.description}`.toLowerCase()
    
    return searchTerms.some(term => textToSearch.includes(term))
  }
}

export default GoogleJobsStructuredScraper
